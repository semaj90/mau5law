# Unified Search Architecture - Evidence Processing System

## Triple-Vector Architecture Overview

This system combines PostgreSQL JSONB + pgvector + Qdrant for maximum performance and flexibility in legal evidence processing and search.

### Core Components

1. **PostgreSQL JSONB + pgvector**: Primary storage with rich metadata + basic vector search
2. **Qdrant**: High-performance vector engine for massive scale semantic search  
3. **GPU Tensor Cache**: Pre-computed embeddings stored in portable formats
4. **QUIC + gRPC**: Low-latency transport with protobuf serialization
5. **PNG Embedding**: Tensors embedded in image artifacts for distribution

## Database Architecture

### PostgreSQL Schema
```sql
CREATE TABLE evidence_files (
  id SERIAL PRIMARY KEY,
  case_id UUID,
  title TEXT,
  storage_bucket TEXT,
  object_name TEXT,
  
  -- JSONB for complex legal metadata (GIN indexed)
  metadata JSONB NOT NULL DEFAULT '{}',
  
  -- pgvector for basic similarity search
  embeddings VECTOR(768),
  
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Optimized indexes
CREATE INDEX idx_evidence_metadata_gin ON evidence_files USING gin (metadata);
CREATE INDEX idx_evidence_embeddings_hnsw ON evidence_files USING hnsw (embeddings vector_cosine_ops);
```

### JSONB Structure Example
```json
{
  "legal": {
    "case_type": "corporate_espionage",
    "jurisdiction": "federal", 
    "classification": "confidential",
    "parties": [
      {"name": "TechCorp Inc", "role": "plaintiff"},
      {"name": "John Smith", "role": "defendant"}
    ]
  },
  "processing": {
    "yolo_detections": [
      {"class": "document", "confidence": 0.95, "bbox": [10, 20, 100, 200]},
      {"class": "signature", "confidence": 0.87, "bbox": [150, 180, 250, 220]}
    ],
    "ocr_results": {
      "text": "CONFIDENTIAL AGREEMENT...",
      "regions": [{"text": "CONFIDENTIAL", "bbox": [25, 30, 120, 45]}]
    },
    "embedding_metadata": {
      "model": "text-embedding-3-small",
      "dimensions": 768,
      "created": "2025-01-15T10:30:00Z"
    }
  }
}
```

## Performance Characteristics

### PostgreSQL JSONB + pgvector
- ✅ Complex metadata queries with JSONB operators (sub-millisecond via GIN index)
- ✅ ACID compliance for legal evidence integrity
- ✅ Integrated single database solution
- ⚠️ Scale limit: ~1M vectors optimal

### Qdrant Vector Engine  
- ✅ Pure speed: 10x faster than pgvector for vector operations
- ✅ Massive scale: 100M+ vectors efficiently
- ✅ Advanced features: quantization, clustering, distributed search
- ⚠️ Additional service complexity

## Enhancing for 100M+ Vectors

### 1. Distributed Qdrant Cluster
```yaml
# docker-compose.yml
version: '3.8'
services:
  qdrant-node1:
    image: qdrant/qdrant:latest
    environment:
      QDRANT__CLUSTER__ENABLED: true
      QDRANT__CLUSTER__NODE_ID: 1
    volumes:
      - ./qdrant_data_1:/qdrant/storage
  
  qdrant-node2:
    image: qdrant/qdrant:latest
    environment:
      QDRANT__CLUSTER__ENABLED: true  
      QDRANT__CLUSTER__NODE_ID: 2
    volumes:
      - ./qdrant_data_2:/qdrant/storage
```

### 2. Vector Quantization & Compression
```python
# Reduce memory usage by 4x with INT8 quantization
collection_config = {
    "vectors": {
        "size": 768,
        "distance": "Cosine"
    },
    "quantization_config": {
        "scalar": {
            "type": "int8",
            "quantile": 0.99,
            "always_ram": True
        }
    }
}
```

### 3. Hierarchical Storage Strategy
```
L0: GPU VRAM Cache (hot tensors, <1ms access)
L1: Redis Cluster (warm metadata, <10ms)  
L2: Qdrant Cluster (vector search, <50ms)
L3: PostgreSQL JSONB (complex queries, <100ms)
L4: MinIO Object Storage (cold archive, <1s)
```

## GPU Tensor Pipeline Architecture

### Canonical Storage Format
```
/artifacts/<id>.meta.json      # manifest (JSONB in Postgres)
          <id>.tensor         # binary blob (FP16/INT8)
          <id>.preview.png    # visual preview with embedded chunk
```

### Tensor Manifest Structure
```json
{
  "id": "evidence_12345_embedding",
  "model": "text-embedding-3-small", 
  "input_hash": "sha256:abc123...",
  "shape": [768],
  "dtype": "fp16",
  "layout": "NCHW",
  "provenance": {
    "hmac": "sha256:def456...",
    "signer": "evidence-processor-v1",
    "created_at": "2025-01-15T10:30:00Z"
  },
  "compression": "brotli"
}
```

### gRPC + Protobuf Transport Schema
```protobuf
syntax = "proto3";
package tensorstore;

message Manifest {
  string id = 1;
  string model = 2;
  repeated int32 shape = 3;
  string dtype = 4; // "fp16","fp32","int8"
  string layout = 5; // "NCHW","NHWC"
  map<string,string> meta = 6;
}

message Chunk {
  string id = 1;
  bytes data = 2;
  int32 index = 3;
  bool last = 4;
}

service TensorStore {
  rpc Put(stream Chunk) returns (Ack);
  rpc Get(GetRequest) returns (stream Chunk);
  rpc QueryByVector(VectorQuery) returns (SearchResults);
}
```

### GPU Cache Library (LRU + VRAM Management)
```go
type GPUCache struct {
    cache    map[string]*DevicePointer
    lru      *list.List
    maxVRAM  int64
    usedVRAM int64
    mutex    sync.RWMutex
}

func (c *GPUCache) GetOrCompute(key string, computeFn func() (*Tensor, error)) (*DevicePointer, error) {
    // Check VRAM cache first (sub-microsecond)
    if ptr, exists := c.cache[key]; exists {
        c.moveToFront(key)
        return ptr, nil
    }
    
    // Compute and store in VRAM
    tensor, err := computeFn()
    if err != nil {
        return nil, err
    }
    
    return c.storeTensor(key, tensor)
}
```

### PNG Tensor Embedding (Portable Artifacts)
```javascript
import { encode, extract } from 'png-chunks-extract';

function embedTensorInPNG(originalPNG, tensor, manifest) {
    const chunks = extract(originalPNG);
    
    // Create custom yoRHa chunk with compressed FP16 tensor
    const manifestData = Buffer.from(JSON.stringify(manifest));
    const tensorData = compressToFP16(tensor);
    
    const yoRHaChunk = {
        name: 'yoRH',
        data: Buffer.concat([
            manifestData,
            Buffer.from([0x00]), // separator
            tensorData
        ])
    };
    
    // Insert after IHDR chunk
    chunks.splice(1, 0, yoRHaChunk);
    
    return encode(chunks);
}
```

## Query Performance Optimization

### Multi-Tier Query Router
```typescript
class UnifiedEvidenceSearch {
  async comprehensiveSearch(query: string, filters: any) {
    const queryEmbedding = await this.embeddings.embed(query);
    
    // Route queries based on type and scale
    if (filters.complex_metadata) {
      // PostgreSQL for rich JSONB queries
      return await this.postgres.semanticSearch(query, filters);
    }
    
    if (filters.vector_count > 1000000) {
      // Qdrant for large-scale vector similarity
      return await this.qdrant.hybridSearch(queryEmbedding, filters);
    }
    
    // Hybrid approach for best of both
    const [pgResults, qdrantResults] = await Promise.all([
      this.postgres.semanticSearch(query, filters),
      this.qdrant.hybridSearch(queryEmbedding, filters)
    ]);
    
    return this.mergeResults(pgResults, qdrantResults);
  }
}
```

### Advanced Query Patterns
```sql
-- Complex legal queries with JSONB + vector similarity
SELECT 
  id,
  title,
  metadata,
  (embeddings <=> $1::vector) AS similarity_distance,
  (1 - (embeddings <=> $1::vector)) AS similarity_score
FROM evidence_files 
WHERE 
  -- JSONB GIN index optimization
  metadata @> '{"legal": {"jurisdiction": "federal"}}'
  AND metadata->'processing'->'yolo_detections' @> '[{"class": "signature"}]'
  -- Full-text search in JSONB
  AND to_tsvector(metadata->'processing'->>'text') @@ plainto_tsquery($2)
  -- Vector similarity with HNSW index
  AND embeddings <=> $1::vector < 0.5
ORDER BY embeddings <=> $1::vector
LIMIT 20;
```

## Detective Mode Video Pipeline

### Storyboard Generation (GPU-Optimized)
```python
class DetectiveVideoGenerator:
    def __init__(self, gpu_cache):
        self.gpu_cache = gpu_cache
        self.batch_size = 4  # RTX 3060Ti optimized
        
    async def generate_keyframes(self, evidence_items):
        # Batch process for GPU efficiency
        prompts = self.create_storyboard_prompts(evidence_items)
        
        keyframes = []
        for batch in self.batch_prompts(prompts, self.batch_size):
            # Reuse cached conditioning tensors
            conditioning = await self.gpu_cache.get_or_compute(
                f"conditioning_{hash(batch)}", 
                lambda: self.compute_conditioning(batch)
            )
            
            # Generate at 512px, upscale later (VRAM optimization)
            frames = await self.diffusion_model.generate(
                prompts=batch,
                conditioning=conditioning,
                size=(512, 512),
                dtype=torch.float16  # FP16 for memory efficiency
            )
            
            keyframes.extend(frames)
            
        return keyframes
```

## Latency Targets & Performance

### System Performance Goals
- **YOLO Detection**: <50ms (GPU-accelerated)
- **OCR Processing**: <100ms (cached) / <2s (fresh)  
- **Embedding Generation**: <200ms (batched)
- **Vector Search**: <10ms (Qdrant) / <50ms (PostgreSQL)
- **gRPC + QUIC**: <5ms network latency
- **GPU Tensor Cache**: <1ms (VRAM hit) / <10ms (load from storage)

### Throughput Optimization
- **FlatBuffers**: Zero-copy serialization = 10x faster than JSON
- **QUIC Multiplexing**: Process 100+ evidence files simultaneously  
- **Multi-tier Caching**: 95%+ cache hit rate for common queries
- **GPU Pipeline**: Parallel YOLO + embedding inference
- **Vector Quantization**: 4x memory reduction with INT8

## Implementation Roadmap

### Phase 1: Core Infrastructure
1. PostgreSQL JSONB + pgvector setup with optimized indexes
2. Basic embedding pipeline with GPU caching
3. gRPC + protobuf transport layer
4. MinIO integration for tensor artifacts

### Phase 2: Advanced Search
1. Qdrant cluster deployment and sync pipeline
2. Multi-tier caching with Redis integration
3. PNG tensor embedding for portable artifacts
4. Advanced query routing and optimization

### Phase 3: Scale & Performance  
1. Distributed Qdrant cluster (100M+ vectors)
2. Vector quantization and compression
3. GPU memory optimization and VRAM caching
4. Detective mode video pipeline with tensor reuse

### Phase 4: Production Hardening
1. HMAC signing and provenance tracking
2. Access control and security layers
3. Monitoring and observability
4. Disaster recovery and backup strategies

## Security & Provenance

### Tensor Integrity
- HMAC-256 signing of all tensor artifacts
- Provenance tracking with model versions and input hashes
- Access control with S3 presigned URLs
- Audit logging for all tensor operations

### Legal Compliance
- GDPR-compliant data handling with JSONB metadata
- Chain of custody tracking in PostgreSQL
- Immutable evidence storage with checksums
- Secure multi-tenant access patterns

This architecture provides a battle-tested foundation for processing and searching massive evidence collections while maintaining legal integrity and sub-10ms query performance.